import requests
import zipfile
import io
import datetime
from bs4 import BeautifulSoup
import re

API_KEY = "577d4d3fff35faf9705ef7383b323d98e87a84bd"

def fetch_insincere_corps():
    print("ğŸ” ìµœê·¼ 6ê°œì›”ê°„ 'ë¶ˆì„±ì‹¤ê³µì‹œë²•ì¸ì§€ì •' ê³µì‹œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    url = "https://opendart.fss.or.kr/api/list.json"
    
    # ìµœê·¼ 6ê°œì›” ì¡°íšŒ
    end_dt = datetime.datetime.now()
    start_dt = end_dt - datetime.timedelta(days=180) 
    
    params = {
        "crtfc_key": API_KEY,
        "bgn_de": start_dt.strftime("%Y%m%d"),
        "end_de": end_dt.strftime("%Y%m%d"),
        "last_reprt_at": "Y", # ìµœì¢…ë³´ê³ ì„œë§Œ
        "page_count": 50,
        "pblntf_detail_ty": "I002" # ê³µì •ìœ„/ê±°ë˜ì†Œ ê³µì‹œ -> ìˆ˜ì‹œê³µì‹œ ìª½ì—ëŠ” ì½”ë“œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë³‘í–‰
    }
    
    # NOTE: ë¶ˆì„±ì‹¤ê³µì‹œëŠ” ìœ í˜• ì½”ë“œê°€ ì• ë§¤í•  ìˆ˜ ìˆì–´ ì „ì²´ ìˆ˜ì‹œê³µì‹œ(I002 ë“±) ì¡ê±°ë‚˜
    # ê·¸ëƒ¥ ì „ì²´ ê²€ìƒ‰ í›„ í…ìŠ¤íŠ¸ í•„í„°ë§ì´ í™•ì‹¤í•¨. ì—¬ê¸°ì„  ê²€ìƒ‰ íš¨ìœ¨ì„ ìœ„í•´ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì—ì„œ í•„í„°ë§.
    
    # Strategy Update: pblntf_detail_ty ì—†ì´ ë‚ ì§œë¡œë§Œ ê¸ì–´ì„œ ì´ë¦„ìœ¼ë¡œ í•„í„°ë§ (ê°€ì¥ í™•ì‹¤)
    del params["pblntf_detail_ty"] 
    
    targets = []
    
    try:
        resp = requests.get(url, params=params).json()
        if resp.get('status') == '000' and 'list' in resp:
            for item in resp['list']:
                if "ë¶ˆì„±ì‹¤ê³µì‹œë²•ì¸ì§€ì •" in item['report_nm'] and "ì˜ˆê³ " not in item['report_nm']:
                     # "ì§€ì •ì˜ˆê³ "ëŠ” í™•ì •ì´ ì•„ë‹ˆë¯€ë¡œ ì œì™¸, "ì§€ì •"ë§Œ í¬í•¨
                     targets.append(item)
        else:
            print(f"âŒ API Error: {resp.get('message')}")
            return
            
        print(f"âœ… ì´ {len(targets)}ê±´ì˜ ì§€ì • ê³µì‹œ ë°œê²¬! ìƒì„¸ ë‚´ìš© ë¶„ì„ ì‹œì‘...\n")
        
        results = []
        
        # 5ê°œë§Œ ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ì˜¤ë˜ ê±¸ë¦¼)
        for idx, item in enumerate(targets[:10]):
            rcept_no = item['rcept_no']
            corp_name = item['corp_name']
            
            print(f"[{idx+1}/{min(len(targets), 10)}] ë¶„ì„ ì¤‘: {corp_name} ...")
            
            detail = parse_insincere_detail(rcept_no)
            results.append(f"## {corp_name}\n- **ê³µì‹œ ì œëª©**: {item['report_nm']}\n- **ìœ„ë°˜/ì§€ì • ì‚¬ìœ **: {detail}\n")
            
        # Save to file
        with open("insincere_report.md", "w", encoding="utf-8") as f:
            f.write(f"# ë¶ˆì„±ì‹¤ê³µì‹œë²•ì¸ ì§€ì • í˜„í™© (ìµœê·¼ 6ê°œì›”)\nì‘ì„±ì¼: {datetime.datetime.now().strftime('%Y-%m-%d')}\n\n")
            f.write("\n".join(results))
            
        print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ! 'insincere_report.md' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
    except Exception as e:
        print(f"âŒ Fail: {e}")

def parse_insincere_detail(rcept_no):
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {"crtfc_key": API_KEY, "rcept_no": rcept_no}
    
    try:
        resp = requests.get(url, params=params)
        with zipfile.ZipFile(io.BytesIO(resp.content)) as z:
            target_file = next((f for f in z.namelist() if f.endswith('.xml') or f.endswith('.html')), None)
            if not target_file: return "ë¬¸ì„œ íŒŒì¼ ì—†ìŒ"
            
            soup = BeautifulSoup(z.read(target_file), 'html.parser')
            text = soup.get_text('\n')
            
            # Simple Text Extraction using Keywords
            # ì°¾ì•„ì•¼ í•  í‚¤ì›Œë“œ: "ë¶ˆì„±ì‹¤ê³µì‹œë²•ì¸ ì§€ì •ë‚´ìš©", "ê³µì‹œìœ„ë°˜ ì œì¬ê¸ˆ", "ë¶€ê³¼ë²Œì "
            # ë³´í†µ í‘œ ì•ˆì— ìˆê±°ë‚˜ "2. ì§€ì •ë‚´ìš©" ì„¹ì…˜ì— ìˆìŒ.
            
            lines = text.split('\n')
            extracted = []
            capture = False
            
            for line in lines:
                line = line.strip()
                if not line: continue
                
                # íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ ë°œê²¬ ì‹œ ìº¡ì²˜ ì‹œì‘
                if any(k in line for k in ["2. ë¶ˆì„±ì‹¤ê³µì‹œë²•ì¸ ì§€ì •ë‚´ìš©", "2. ì§€ì •ë‚´ìš©", "2. ì§€ì •ë‚´ì—­"]):
                    capture = True
                    continue
                
                # 3ë²ˆ ì„¹ì…˜ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                if "3." in line and capture: 
                    break
                    
                if capture:
                    # ë„ˆë¬´ ê¸´ ë¼ì¸(Base64 ë“±) ì œì™¸
                    if len(line) < 200:
                        extracted.append(line)
                        
            if not extracted:
                # ì„¹ì…˜ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš° (HTML êµ¬ì¡°ê°€ ë‹¤ë¥¼ ë•Œ) -> "ì‚¬ìœ " í‚¤ì›Œë“œ ì£¼ë³€ íƒìƒ‰
                for i, line in enumerate(lines):
                    if "ìœ„ë°˜ë‚´ìš©" in line or "ì§€ì •ì‚¬ìœ " in line:
                         extracted.append(line)
                         if i+1 < len(lines): extracted.append(lines[i+1])
            
            if not extracted:
                return "ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ (ì„œì‹ ë³µì¡í•¨)"
                
            return " ".join(extracted[:10]) # ê¸¸ë©´ ìë¦„
            
    except Exception as e:
        return f"íŒŒì‹± ì—ëŸ¬: {str(e)}"

if __name__ == "__main__":
    fetch_insincere_corps()
